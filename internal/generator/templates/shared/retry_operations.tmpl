// Shared retry operation utilities
// These functions eliminate duplication across repositories and provide consistent retry patterns
// Available for both generated repositories and custom implementer extensions

import (
	"context"
	"errors"
	"fmt"
	"strings"
	"time"

	"github.com/jackc/pgx/v5/pgconn"
)

// RetryConfig holds configuration for retry operations
type RetryConfig struct {
	MaxRetries int
	BaseDelay  time.Duration
}

// DefaultRetryConfig provides the default retry configuration used by all repositories
var DefaultRetryConfig = RetryConfig{
	MaxRetries: 3,
	BaseDelay:  100 * time.Millisecond,
}

// RetryOperation executes a single-result database operation with retry logic
// This eliminates duplication across all *WithRetry methods in repositories
func RetryOperation[T any](ctx context.Context, config RetryConfig, operation string, fn func(context.Context) (T, error)) (T, error) {
	var zero T
	backoff := config.BaseDelay

	for attempt := 0; attempt < config.MaxRetries; attempt++ {
		result, err := fn(ctx)
		if err == nil {
			return result, nil
		}

		// Don't retry certain types of errors
		if !ShouldRetryError(err) {
			return zero, err
		}

		// Don't retry on last attempt
		if attempt == config.MaxRetries-1 {
			return zero, fmt.Errorf("operation %s failed after %d attempts: %w", operation, config.MaxRetries, err)
		}

		// Wait with exponential backoff
		select {
		case <-ctx.Done():
			return zero, fmt.Errorf("operation %s cancelled during retry: %w", operation, ctx.Err())
		case <-time.After(backoff):
			backoff *= 2
		}
	}

	return zero, fmt.Errorf("operation %s failed after %d attempts", operation, config.MaxRetries)
}

// RetryOperationSlice executes a slice-result database operation with retry logic
// This eliminates duplication across all slice-returning *WithRetry methods in repositories
func RetryOperationSlice[T any](ctx context.Context, config RetryConfig, operation string, fn func(context.Context) ([]T, error)) ([]T, error) {
	backoff := config.BaseDelay

	for attempt := 0; attempt < config.MaxRetries; attempt++ {
		result, err := fn(ctx)
		if err == nil {
			return result, nil
		}

		// Don't retry certain types of errors
		if !ShouldRetryError(err) {
			return nil, err
		}

		// Don't retry on last attempt
		if attempt == config.MaxRetries-1 {
			return nil, fmt.Errorf("operation %s failed after %d attempts: %w", operation, config.MaxRetries, err)
		}

		// Wait with exponential backoff
		select {
		case <-ctx.Done():
			return nil, fmt.Errorf("operation %s cancelled during retry: %w", operation, ctx.Err())
		case <-time.After(backoff):
			backoff *= 2
		}
	}

	return nil, fmt.Errorf("operation %s failed after %d attempts", operation, config.MaxRetries)
}

// ShouldRetryError determines if an error is worth retrying
// This function is shared across all retry operations for consistent retry logic
func ShouldRetryError(err error) bool {
	// Retry on connection errors and timeouts
	if errors.Is(err, context.DeadlineExceeded) {
		return true
	}

	// Check for PostgreSQL connection errors
	var pgErr *pgconn.PgError
	if errors.As(err, &pgErr) {
		switch pgErr.Code {
		case "40001": // serialization_failure
			return true
		case "40P01": // deadlock_detected
			return true
		case "53000": // insufficient_resources
			return true
		case "53100": // disk_full
			return true
		case "53200": // out_of_memory
			return true
		case "53300": // too_many_connections
			return true
		default:
			return false
		}
	}

	// Retry on connection-related errors
	if strings.Contains(err.Error(), "connection") && 
	   (strings.Contains(err.Error(), "closed") || 
	    strings.Contains(err.Error(), "reset") ||
	    strings.Contains(err.Error(), "timeout")) {
		return true
	}

	return false
} 